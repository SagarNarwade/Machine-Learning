# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UDRnMOtxYkBi35R6dgAQVE2CF96hO0Nj

Support Vector Machine With Python To Heart Disease.

'target' is a instance to be classified in 1 or 0.

Import Libraries and Load Dataset
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

df = pd.read_csv('Heart Disease.csv')

df.head()

df.isnull().sum()

df.value_counts('target')

df.value_counts('target').iloc[0]/len(df)

"""Visualisation"""

import plotly.express as ex

fig = ex.histogram(x=df['target'],color=df['sex'])
fig.show()

df.corr()['target'].sort_values()

plt.figure(figsize=(20,12))
sns.countplot(x=df['age'],hue=df['target'])

"""Train Test Split"""

X = df.drop(['target','sex','age','trestbps','chol','fbs','restecg'],axis=1)
y = df['target']

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.19, random_state=101)

"""Creating a Model"""

from sklearn.svm import SVC

model = SVC()

model.fit(X_train,y_train)





predictions = model.predict(X_test)

"""Model Evaluation"""

from sklearn.metrics import classification_report,confusion_matrix

print(classification_report(y_test,predictions))

print(confusion_matrix(y_test,predictions))

"""Testing a model with random data"""

a=pd.DataFrame(X_train)

a=a.iloc[57]

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

X_train= scaler.fit_transform(X_train)

X_test= scaler.transform(X_test)

a =scaler.transform(a.values.reshape(1,7))

print("Predictated Value With Current Model: ",int(model.predict(a)))

print("Original Value: ",int(pd.DataFrame(y_train).iloc[57]))

"""# Gridsearch

Finding the right parameters (like what C or gamma values to use) is a tricky task! But luckily, we can be a little lazy and just try a bunch of combinations and see what works best! This idea of creating a 'grid' of parameters and just trying out all the possible combinations is called a Gridsearch, this method is common enough that Scikit-learn has this functionality built in with GridSearchCV! The CV stands for cross-validation which is the

GridSearchCV takes a dictionary that describes the parameters that should be tried and a model to train. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested. 
"""

param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']}

from sklearn.model_selection import GridSearchCV

"""One of the great things about GridSearchCV is that it is a meta-estimator. It takes an estimator like SVC, and creates a new estimator, that behaves exactly the same - in this case, like a classifier. You should add refit=True and choose verbose to whatever number you want, higher the number, the more verbose (verbose just means the text output describing the process)."""

grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)

# May take awhile!
grid.fit(X_train,y_train)

grid.best_params_

grid.best_estimator_

grid_predictions = grid.predict(X_test)

print(confusion_matrix(y_test,grid_predictions))

print(classification_report(y_test,grid_predictions))

"""Testing a Grid Model with random data"""

a=pd.DataFrame(X_train)

a=a.iloc[89]

from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

X_train= scaler.fit_transform(X_train)

X_test= scaler.transform(X_test)

a =scaler.transform(a.values.reshape(1,7))
print("Predictated Value With Current Model: ",int(grid.predict(a)))
print("Original Value: ",int(pd.DataFrame(y_train).iloc[89]))